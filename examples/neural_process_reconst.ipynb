{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from tensorboardX import SummaryWriter\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "seed = 1\n",
    "\n",
    "context_num = 10 # length of contexts\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Tars.distributions import Normal, Bernoulli\n",
    "from Tars.distributions.divergences import KullbackLeibler\n",
    "from Tars.models import VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_coordinated_mnist(x):\n",
    "    # input (torch.Tensor) : x(batch_size, 1, 28, 28)\n",
    "    # output（numpy）: x_coordinate(seq_len=28*28, batch_size, 2), y_coordinate(seq_len=28*28, batch_size, 1)\n",
    "    \n",
    "    batch_size = x.shape[0]\n",
    "    \n",
    "    X = np.tile(np.arange(28), (batch_size, 1))\n",
    "    Y = np.tile(np.arange(28), (1, 1))\n",
    "    xx, yy = np.asarray(np.meshgrid(X,Y))\n",
    "    xx = xx.reshape(1,batch_size,28*28).T\n",
    "    yy = yy.reshape(28*28,batch_size, 1)\n",
    "    \n",
    "    x_coordinate = np.concatenate([xx, yy],axis=2)\n",
    "    y_coordinate = x.view(-1, 784).t().data.numpy()[:,:,np.newaxis]\n",
    "\n",
    "    return x_coordinate, y_coordinate\n",
    "\n",
    "def shuffle_dim(x, y, random_seed=1234, shuffle_each_example=True):\n",
    "\n",
    "    if shuffle_each_example:\n",
    "        x = x.swapaxes(0, 1)\n",
    "        y = y.swapaxes(0, 1)\n",
    "\n",
    "        dim0, dim1, _ = x.shape\n",
    "        indices = np.indices((dim0, dim1))\n",
    "        rows = indices[0]\n",
    "    \n",
    "        cols = [np.random.permutation(dim1) for _ in range(dim0)]\n",
    "        x = x[rows, cols]\n",
    "        y = y[rows, cols]\n",
    "    \n",
    "        x = x.swapaxes(0, 1)\n",
    "        y = y.swapaxes(0, 1)\n",
    "        \n",
    "    else:\n",
    "        np.random.seed(1234)\n",
    "        dim0, _, _ = x.shape\n",
    "        rows = np.random.permutation(dim0)\n",
    "        x = x[rows]\n",
    "        y = y[rows]\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "def split_context_target(x, y, context_num=100, device=\"cpu\", shuffle_each_example=True):\n",
    "    x, y = shuffle_dim(x, y, shuffle_each_example=shuffle_each_example)\n",
    "    x_context = torch.Tensor(x[:context_num]).to(device)\n",
    "    y_context = torch.Tensor(y[:context_num]).to(device)\n",
    "    \n",
    "    x_target = torch.Tensor(x[context_num:]).to(device)\n",
    "    y_target = torch.Tensor(y[context_num:]).to(device)\n",
    "#    x_target = torch.Tensor(x).to(device)\n",
    "#    y_target = torch.Tensor(y).to(device)\n",
    "    \n",
    "    return x_context, y_context, x_target, y_target\n",
    "\n",
    "def convert_plot_img(x, y):\n",
    "    seq_len = x.shape[0]\n",
    "    x = x.astype(\"int32\")\n",
    "    \n",
    "    dummy_data = np.ones((28, 28),dtype=\"float32\")*-1.    \n",
    "    for i in range(seq_len):\n",
    "        dummy_data[tuple(x[i])] = y[i]\n",
    "    return dummy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import PIL.Image\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "def plot_image(x_c, y_c, x_t, y_t, image_id=0):\n",
    "\n",
    "    plt.subplot(1,5,1)\n",
    "    img = convert_plot_img(x_t[:,image_id].cpu().data.numpy(), y_t[:,image_id].cpu().data.numpy())\n",
    "    plt.imshow(img.T, cmap=\"gray\")\n",
    "\n",
    "    plt.subplot(1,5,2)\n",
    "    z = q.sample({\"x_c\": x_c, \"y_c\": y_c, \"x_t\": x_t, \"y_t\": y_t})[\"z\"]\n",
    "    pred_y_t = _p.sample_mean({\"x_t\": x_t, \"z\": z})\n",
    "    img = convert_plot_img(x_t[:,image_id].cpu().data.numpy(), pred_y_t[:,image_id].cpu().data.numpy())\n",
    "    plt.imshow(img.T, cmap=\"gray\")\n",
    "    \n",
    "    plt.subplot(1,5,3)\n",
    "    z = q.sample({\"x_c\": x_c, \"y_c\": y_c, \"x_t\": x_t, \"y_t\": y_t})[\"z\"]\n",
    "    pred_y_t = _p.sample_mean({\"x_t\": x_t, \"z\": z})\n",
    "    img = convert_plot_img(x_t[:,image_id].cpu().data.numpy(), pred_y_t[:,image_id].cpu().data.numpy())\n",
    "    plt.imshow(img.T, cmap=\"gray\")\n",
    "    \n",
    "    plt.subplot(1,5,4)\n",
    "    z = q.sample({\"x_c\": x_c, \"y_c\": y_c, \"x_t\": x_t, \"y_t\": y_t})[\"z\"]\n",
    "    pred_y_t = _p.sample_mean({\"x_t\": x_t, \"z\": z})\n",
    "    img = convert_plot_img(x_t[:,image_id].cpu().data.numpy(), pred_y_t[:,image_id].cpu().data.numpy())\n",
    "    plt.imshow(img.T, cmap=\"gray\")    \n",
    "\n",
    "\n",
    "    plt.subplot(1,5,5)\n",
    "    img = convert_plot_img(x_c[:,image_id].cpu().data.numpy(), y_c[:,image_id].cpu().data.numpy())\n",
    "    plt.imshow(img.T, cmap=\"gray\")  \n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='jpeg')\n",
    "    buf.seek(0)    \n",
    "    return buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 2 #x_cordinate_dim\n",
    "y_dim = 1\n",
    "z_dim = 64\n",
    "h_dim = 512\n",
    "\n",
    "class Representation(nn.Module):\n",
    "    def __init__(self, x_dim, y_dim):\n",
    "        super(Representation, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(x_dim + y_dim, h_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, h_dim)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(h_dim)        \n",
    "        self.bn2 = nn.BatchNorm1d(h_dim)        \n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        # x : (batch_size, x_dim)\n",
    "        # y : (batch_size, y_dim)\n",
    "        \n",
    "        h = F.relu(self.bn1(self.fc1(torch.cat([x,y], 1))))\n",
    "        h = F.relu(self.bn2(self.fc2(h)))\n",
    "        \n",
    "        # h : (batch_size, h_dim)\n",
    "        return h\n",
    "    \n",
    "rep = Representation(x_dim, y_dim)\n",
    "\n",
    "# inference model q(z|x_c, y_c, x_t, y_t)\n",
    "class Inference(Normal):\n",
    "    def __init__(self):\n",
    "        super(Inference, self).__init__(cond_var=[\"x_c\", \"y_c\", \"x_t\", \"y_t\"], var=[\"z\"])        \n",
    "        \n",
    "        self.h = rep\n",
    "        self.fc31 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc32 = nn.Linear(h_dim, z_dim)\n",
    "\n",
    "    def forward(self, x_c, y_c, x_t, y_t):\n",
    "        # x_c : (context_num, batch_size, x_dim)\n",
    "        # y_c : (context_num, batch_size, y_dim)\n",
    "        # x_t : (28*28 - context_num, batch_size, x_dim)   \n",
    "        # x_t : (28*28 - context_num, batch_size, y_dim)\n",
    "        \n",
    "        _batch_size = x_c.shape[1]\n",
    "                        \n",
    "        x_c = x_c.view(-1, x_dim)\n",
    "        y_c = y_c.view(-1, y_dim)\n",
    "        x_t = x_t.view(-1, x_dim)\n",
    "        y_t = y_t.view(-1, y_dim)       \n",
    "        \n",
    "        r_c = self.h(x_c, y_c).view(-1, _batch_size, h_dim)\n",
    "        r_t = self.h(x_t, y_t).view(-1, _batch_size, h_dim)\n",
    "        \n",
    "        r = torch.cat([r_c, r_t], dim=0)\n",
    "        r = torch.mean(r, dim=0)\n",
    "\n",
    "        # r : (batch_size, z_dim)\n",
    "        return {\"loc\": self.fc31(r), \"scale\": F.softplus(self.fc32(r))}    \n",
    "    \n",
    "# generative model p(y_t|x_t, z)    \n",
    "class Generator(Bernoulli):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__(cond_var=[\"x_t\", \"z\"], var=[\"y_t\"], sequential=True)\n",
    "\n",
    "        self.fc1 = nn.Linear(z_dim+x_dim, h_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, h_dim)\n",
    "        self.fc3 = nn.Linear(h_dim, y_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(h_dim)        \n",
    "        self.bn2 = nn.BatchNorm1d(h_dim)        \n",
    "\n",
    "    def g(self, x_t, z):\n",
    "        h = F.relu(self.bn1(self.fc1(torch.cat([z, x_t], 1))))\n",
    "        h = F.relu(self.bn2(self.fc2(h)))\n",
    "        return F.sigmoid(self.fc3(h))\n",
    "        \n",
    "    def forward(self, x_t, z):\n",
    "        # x_t : (28*28 - context_num, batch_size, x_dim)\n",
    "        # z : (batch_size, z_dim)        \n",
    "        \n",
    "        y_t = [self.g(_x_t, z)[np.newaxis,:,:] for _x_t in x_t]\n",
    "        y_t = torch.cat(y_t)\n",
    "\n",
    "        # y_t : (28*28 - context_num, batch_size, y_dim)\n",
    "        return {\"probs\": y_t} \n",
    "    \n",
    "# prior model p(z)\n",
    "loc = torch.tensor(0.).to(device)\n",
    "scale = torch.tensor(1.).to(device)\n",
    "prior = Normal(loc=loc, scale=scale, var=[\"z\"], dim=z_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_p = Generator()\n",
    "q = Inference()\n",
    "\n",
    "p = _p * prior\n",
    "\n",
    "print(p.prob_factorized_text, q.prob_factorized_text)\n",
    "\n",
    "p.to(device)\n",
    "q.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl = KullbackLeibler(q, prior)\n",
    "model = VAE(q, _p, regularizer=[kl], optimizer=optim.Adam, optimizer_params={\"lr\":1e-3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    train_loss = 0    \n",
    "    t = tqdm(train_loader)\n",
    "    for batch_idx, (data, _) in enumerate(t):\n",
    "        t.set_description('Epoch: {}'.format(epoch))\n",
    "        \n",
    "        x, y = get_coordinated_mnist(data)\n",
    "        x_c, y_c, x_t, y_t = split_context_target(x, y, context_num=context_num, device=device)\n",
    "        \n",
    "        lower_bound, loss = model.train({\"x_c\": x_c, \"y_c\": y_c, \"x_t\": x_t, \"y_t\": y_t})\n",
    "        train_loss += loss\n",
    "        \n",
    "        t.set_postfix(loss=loss.item())\n",
    " \n",
    "    train_loss = train_loss * train_loader.batch_size / len(train_loader.dataset)\n",
    "    print('Epoch: {} Train loss: {:.4f}'.format(epoch, train_loss))\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    test_loss = 0\n",
    "    for i, (data, _) in enumerate(test_loader):\n",
    "        x, y = get_coordinated_mnist(data)\n",
    "        x_c, y_c, x_t, y_t = split_context_target(x, y, context_num=context_num, device=device)\n",
    "\n",
    "        lower_bound, loss = model.test({\"x_c\": x_c, \"y_c\": y_c, \"x_t\": x_t, \"y_t\": y_t})        \n",
    "        test_loss += loss\n",
    "\n",
    "    test_loss = test_loss * test_loader.batch_size / len(test_loader.dataset)\n",
    "    print('Test loss: {:.4f}'.format(test_loss))\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "x_original = test_loader.dataset.test_data[:2]\n",
    "x, y = get_coordinated_mnist(x_original)\n",
    "x_c, y_c, x_t, y_t = split_context_target(x, y, context_num=context_num, device=device)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    plot_buf = plot_image(x_c, y_c, x_t, y_t)\n",
    "\n",
    "    image = PIL.Image.open(plot_buf)\n",
    "    image = ToTensor()(image).unsqueeze(0)\n",
    "    \n",
    "    writer.add_image('Image', image, epoch)\n",
    "    \n",
    "    train_loss = train(epoch)\n",
    "    test_loss = test(epoch)\n",
    "    \n",
    "    writer.add_scalar('train_loss', train_loss.item(), epoch)\n",
    "    writer.add_scalar('test_loss', test_loss.item(), epoch)    \n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
